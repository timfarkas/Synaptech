{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing & Analysing Wavelet transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import mean pooled data\n",
    "- Importing and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from 11 subjects...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed7b878afd648dfb4c364a9b28473a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading subjects:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shapes:\n",
      "EEG data: torch.Size([74, 275, 25706])\n",
      "  - 74 channels\n",
      "  - 275 timepoints per window\n",
      "  - 25706 total windows\n",
      "  - dtype: torch.float16\n",
      "\n",
      "MAG data: torch.Size([102, 275, 25706])\n",
      "  - 102 channels\n",
      "  - 275 timepoints per window\n",
      "  - 25706 total windows\n",
      "  - dtype: torch.float16\n",
      "\n",
      "EEG Statistics:\n",
      "Mean: 0.001\n",
      "Std: 1.049\n",
      "Min: -122.562\n",
      "Max: 77.312\n",
      "\n",
      "MAG Statistics:\n",
      "Mean: -0.000\n",
      "Std: 0.060\n",
      "Min: -5.055\n",
      "Max: 4.867\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "DATASET_PATH = os.getenv('DATASET_PATH')\n",
    "\n",
    "# ONLY IMPLEMENTS TRAINING DATA ATM\n",
    "def load_and_concat_shards(dataset_path, mode='train'):\n",
    "    \"\"\"\n",
    "    Loads and concatenates all EEG and MAG shards from the specified dataset path and mode.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset root directory\n",
    "        mode (str): One of 'train', 'val', or 'test'\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (concatenated_eeg, concatenated_mag) tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    eeg_tensors = []\n",
    "    mag_tensors = []\n",
    "    \n",
    "    # Get all subject folders in the specified mode\n",
    "    mode_path = Path(dataset_path) / mode\n",
    "    subject_folders = sorted([f for f in mode_path.iterdir() if f.is_dir()])\n",
    "    \n",
    "    print(f\"Loading {mode} data from {len(subject_folders)} subjects...\")\n",
    "    \n",
    "    # Iterate through each subject folder\n",
    "    for subject_folder in tqdm(subject_folders, desc=\"Loading subjects\"):\n",
    "        # Load EEG shards\n",
    "        eeg_shard_folder = subject_folder / \"EEG_shards\"\n",
    "        if eeg_shard_folder.exists():\n",
    "            eeg_files = sorted(eeg_shard_folder.glob(\"*.pt\"))\n",
    "            for eeg_file in eeg_files:\n",
    "                eeg_tensor = torch.load(eeg_file)\n",
    "                eeg_tensors.append(eeg_tensor)\n",
    "        \n",
    "        # Load MAG shards\n",
    "        mag_shard_folder = subject_folder / \"MAG_shards\"\n",
    "        if mag_shard_folder.exists():\n",
    "            mag_files = sorted(mag_shard_folder.glob(\"*.pt\"))\n",
    "            for mag_file in mag_files:\n",
    "                mag_tensor = torch.load(mag_file)\n",
    "                mag_tensors.append(mag_tensor)\n",
    "    \n",
    "    # Concatenate all tensors\n",
    "    if eeg_tensors:\n",
    "        concatenated_eeg = torch.cat(eeg_tensors, dim=2)  # Concatenate along windows dimension\n",
    "    else:\n",
    "        concatenated_eeg = None\n",
    "        \n",
    "    if mag_tensors:\n",
    "        concatenated_mag = torch.cat(mag_tensors, dim=2)  # Concatenate along windows dimension\n",
    "    else:\n",
    "        concatenated_mag = None\n",
    "    \n",
    "    return concatenated_eeg, concatenated_mag\n",
    "\n",
    "# Load and concatenate the data\n",
    "dataset_path = DATASET_PATH  # Adjust this path as needed\n",
    "eeg_data, mag_data = load_and_concat_shards(dataset_path, mode='train')\n",
    "\n",
    "# Print information about the tensors\n",
    "print(\"\\nData shapes:\")\n",
    "if eeg_data is not None:\n",
    "    print(f\"EEG data: {eeg_data.shape}\")\n",
    "    print(f\"  - {eeg_data.shape[0]} channels\")\n",
    "    print(f\"  - {eeg_data.shape[1]} timepoints per window\")\n",
    "    print(f\"  - {eeg_data.shape[2]} total windows\")\n",
    "    print(f\"  - dtype: {eeg_data.dtype}\")\n",
    "else:\n",
    "    print(\"No EEG data found\")\n",
    "\n",
    "if mag_data is not None:\n",
    "    print(f\"\\nMAG data: {mag_data.shape}\")\n",
    "    print(f\"  - {mag_data.shape[0]} channels\")\n",
    "    print(f\"  - {mag_data.shape[1]} timepoints per window\")\n",
    "    print(f\"  - {mag_data.shape[2]} total windows\")\n",
    "    print(f\"  - dtype: {mag_data.dtype}\")\n",
    "else:\n",
    "    print(\"No MAG data found\")\n",
    "\n",
    "# Optional: Print some basic statistics\n",
    "if eeg_data is not None:\n",
    "    print(\"\\nEEG Statistics:\")\n",
    "    print(f\"Mean: {eeg_data.float().mean():.3f}\")\n",
    "    print(f\"Std: {eeg_data.float().std():.3f}\")\n",
    "    print(f\"Min: {eeg_data.float().min():.3f}\")\n",
    "    print(f\"Max: {eeg_data.float().max():.3f}\")\n",
    "\n",
    "if mag_data is not None:\n",
    "    print(\"\\nMAG Statistics:\")\n",
    "    print(f\"Mean: {mag_data.float().mean():.3f}\")\n",
    "    print(f\"Std: {mag_data.float().std():.3f}\")\n",
    "    print(f\"Min: {mag_data.float().min():.3f}\")\n",
    "    print(f\"Max: {mag_data.float().max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6bc6de5c847bc9af3554fbd411a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=275, description='Time Frames', max=275, min=1), IntSlider(value=0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "@interact(\n",
    "    time_frames=widgets.IntSlider(min=1, max=275, step=1, value=275, description='Time Frames'),\n",
    "    window_index=widgets.IntSlider(min=0, max=0 if eeg_data is None else eeg_data.shape[2]-1, step=1, value=0, description='Window')\n",
    ")\n",
    "def dynamic_plot(time_frames, window_index):\n",
    "    \"\"\"\n",
    "    Dynamically plot the first `time_frames` samples from EEG channel 13 and \n",
    "    MAG channel 21 for the requested window_index, using ipywidgets for \n",
    "    interactive sliders in a Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    \n",
    "    if eeg_data is not None:\n",
    "        # EEG Channel 13\n",
    "        eeg_slice = eeg_data[13, :time_frames, window_index].cpu().numpy() if eeg_data.is_cuda else eeg_data[13, :time_frames, window_index].numpy()\n",
    "        axs[0].plot(eeg_slice, label='EEG Ch 13', color='red')  # Changed to red\n",
    "        axs[0].set_title(f'EEG channel 13 (Window {window_index})')\n",
    "        axs[0].legend()\n",
    "\n",
    "    if mag_data is not None:\n",
    "        # MAG Channel 21\n",
    "        mag_slice = mag_data[21, :time_frames, window_index].cpu().numpy() if mag_data.is_cuda else mag_data[21, :time_frames, window_index].numpy()\n",
    "        axs[1].plot(mag_slice, label='MAG Ch 21', color='blue')  # Changed to blue\n",
    "        axs[1].set_title(f'MAG channel 21 (Window {window_index})')\n",
    "        axs[1].legend()\n",
    "\n",
    "    axs[1].set_xlabel('Sample Index')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6eb899176d40bc84905da8895222d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Window', max=25705), Dropdown(description='View Type:', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def compute_wavelet_transform(data, sampling_rate=275, frequencies=None, wavelet='cmor1.5-1.0'):\n",
    "    \"\"\"\n",
    "    Compute the continuous wavelet transform for a signal.\n",
    "    \n",
    "    Args:\n",
    "        data: 1D array of signal values\n",
    "        sampling_rate: sampling rate of the signal (default 250 Hz)\n",
    "        frequencies: frequency range to analyze (default: None, will create automatically)\n",
    "        wavelet: wavelet to use (default: complex Morlet wavelet)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (wavelet_coeffs, frequencies)\n",
    "    \"\"\"\n",
    "    if frequencies is None:\n",
    "        frequencies = np.logspace(np.log10(1), np.log10(100), num=50)\n",
    "    \n",
    "    scales = pywt.frequency2scale(wavelet, frequencies / sampling_rate)\n",
    "    coefficients, _ = pywt.cwt(data, scales, wavelet)\n",
    "    \n",
    "    return coefficients, frequencies\n",
    "\n",
    "def plot_wavelet_visualizations(eeg_data, mag_data, window_idx=0, eeg_channel=13, mag_channel=21, cmap='inferno'):\n",
    "    \"\"\"\n",
    "    Multiple visualizations of wavelet analysis for EEG and MEG signals\n",
    "    \"\"\"\n",
    "    # Clear previous plots\n",
    "    plt.close('all')\n",
    "    \n",
    "    # Extract signals\n",
    "    eeg_signal = eeg_data[eeg_channel, :, window_idx].cpu().numpy()\n",
    "    mag_signal = mag_data[mag_channel, :, window_idx].cpu().numpy()\n",
    "    \n",
    "    # Compute wavelets\n",
    "    eeg_coeffs, freqs = compute_wavelet_transform(eeg_signal)\n",
    "    mag_coeffs, _ = compute_wavelet_transform(mag_signal)\n",
    "    \n",
    "    time = np.arange(len(eeg_signal)) / 250\n",
    "    \n",
    "    # Create figure with 3 rows, 2 columns\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # 1. Standard Scalogram (heat map)\n",
    "    ax1 = plt.subplot(321)\n",
    "    im1 = ax1.pcolormesh(time, freqs, np.abs(eeg_coeffs), shading='gouraud', cmap=cmap)\n",
    "    ax1.set_ylabel('Frequency (Hz)')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_title('EEG Scalogram')\n",
    "    plt.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    ax2 = plt.subplot(322)\n",
    "    im2 = ax2.pcolormesh(time, freqs, np.abs(mag_coeffs), shading='gouraud', cmap=cmap)\n",
    "    ax2.set_ylabel('Frequency (Hz)')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_title('MEG Scalogram')\n",
    "    plt.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    # 2. 3D Surface Plot\n",
    "    ax3 = plt.subplot(323, projection='3d')\n",
    "    time_mesh, freq_mesh = np.meshgrid(time, freqs)\n",
    "    ax3.plot_surface(time_mesh, freq_mesh, np.abs(eeg_coeffs), cmap=cmap, alpha=0.8)\n",
    "    ax3.set_ylabel('Frequency (Hz)')\n",
    "    ax3.set_title('EEG 3D Wavelet')\n",
    "    ax3.set_yscale('log')\n",
    "    \n",
    "    ax4 = plt.subplot(324, projection='3d')\n",
    "    ax4.plot_surface(time_mesh, freq_mesh, np.abs(mag_coeffs), cmap=cmap, alpha=0.8)\n",
    "    ax4.set_ylabel('Frequency (Hz)')\n",
    "    ax4.set_title('MEG 3D Wavelet')\n",
    "    ax4.set_yscale('log')\n",
    "    \n",
    "    # 3. Contour Plot\n",
    "    ax5 = plt.subplot(325)\n",
    "    cont1 = ax5.contourf(time, freqs, np.abs(eeg_coeffs), levels=20, cmap=cmap)\n",
    "    ax5.set_ylabel('Frequency (Hz)')\n",
    "    ax5.set_yscale('log')\n",
    "    ax5.set_title('EEG Contour')\n",
    "    plt.colorbar(cont1, ax=ax5)\n",
    "    \n",
    "    ax6 = plt.subplot(326)\n",
    "    cont2 = ax6.contourf(time, freqs, np.abs(mag_coeffs), levels=20, cmap=cmap)\n",
    "    ax6.set_ylabel('Frequency (Hz)')\n",
    "    ax6.set_yscale('log')\n",
    "    ax6.set_title('MEG Contour')\n",
    "    plt.colorbar(cont2, ax=ax6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "@interact(\n",
    "    window_index=widgets.IntSlider(\n",
    "        min=0, \n",
    "        max=eeg_data.shape[2]-1, \n",
    "        step=1, \n",
    "        value=0, \n",
    "        description='Window'\n",
    "    ),\n",
    "    visualization_type=widgets.Dropdown(\n",
    "        options=['3d', 'standard', 'contour', 'all'],\n",
    "        value='3d',  # Default to '3d' now\n",
    "        description='View Type:'\n",
    "    )\n",
    ")\n",
    "def plot_interactive_wavelet_viz(window_index, visualization_type='3d'):\n",
    "    \"\"\"\n",
    "    Interactive function for visualizing different wavelet plots for EEG and MEG.\n",
    "    Using RdYlBu_r colormap: Blue (low) -> White (medium) -> Red (high)\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Extract signals\n",
    "    eeg_signal = eeg_data[13, :, window_index].cpu().numpy()\n",
    "    mag_signal = mag_data[21, :, window_index].cpu().numpy()\n",
    "    eeg_coeffs, freqs = compute_wavelet_transform(eeg_signal)\n",
    "    mag_coeffs, _ = compute_wavelet_transform(mag_signal)\n",
    "    time = np.arange(len(eeg_signal)) / 250\n",
    "    \n",
    "    if visualization_type == '3d':\n",
    "        # Create a larger figure for better 3D visualization\n",
    "        plt.close('all')\n",
    "        fig = plt.figure(figsize=(20, 8))\n",
    "        \n",
    "        # EEG 3D Plot\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        time_mesh, freq_mesh = np.meshgrid(time, freqs)\n",
    "        \n",
    "        surf1 = ax1.plot_surface(time_mesh, freq_mesh, np.abs(eeg_coeffs), \n",
    "                               cmap='RdYlBu_r', alpha=0.8,\n",
    "                               rstride=1, cstride=1,  # Reduce stride for smoother surface\n",
    "                               linewidth=0, antialiased=True)\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax1.set_xlabel('Time (s)')\n",
    "        ax1.set_ylabel('Frequency (Hz)')\n",
    "        ax1.set_zlabel('Magnitude')\n",
    "        ax1.set_title('EEG Wavelet - 3D')\n",
    "        \n",
    "        # Set the viewing angle\n",
    "        ax1.view_init(elev=30, azim=45)\n",
    "        \n",
    "        # Add colorbar\n",
    "        fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "        \n",
    "        # MEG 3D Plot\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        \n",
    "        surf2 = ax2.plot_surface(time_mesh, freq_mesh, np.abs(mag_coeffs), \n",
    "                               cmap='RdYlBu_r', alpha=0.8,\n",
    "                               rstride=1, cstride=1,  # Reduce stride for smoother surface\n",
    "                               linewidth=0, antialiased=True)\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax2.set_xlabel('Time (s)')\n",
    "        ax2.set_ylabel('Frequency (Hz)')\n",
    "        ax2.set_zlabel('Magnitude')\n",
    "        ax2.set_title('MEG Wavelet - 3D')\n",
    "        \n",
    "        # Set the viewing angle\n",
    "        ax2.view_init(elev=30, azim=45)\n",
    "        \n",
    "        # Add colorbar\n",
    "        fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "        \n",
    "        plt.tight_layout(w_pad=5)  # Increase spacing between subplots\n",
    "        \n",
    "    elif visualization_type == 'standard':\n",
    "        plt.close('all')\n",
    "        fig = plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        ax1 = plt.subplot(121)\n",
    "        im1 = ax1.pcolormesh(time, freqs, np.abs(eeg_coeffs), \n",
    "                            shading='gouraud', cmap='RdYlBu_r')\n",
    "        ax1.set_title('EEG Wavelet - Standard')\n",
    "        ax1.set_yscale('log')\n",
    "        plt.colorbar(im1, ax=ax1)\n",
    "        \n",
    "        ax2 = plt.subplot(122)\n",
    "        im2 = ax2.pcolormesh(time, freqs, np.abs(mag_coeffs), \n",
    "                            shading='gouraud', cmap='RdYlBu_r')\n",
    "        ax2.set_title('MEG Wavelet - Standard')\n",
    "        ax2.set_yscale('log')\n",
    "        plt.colorbar(im2, ax=ax2)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    elif visualization_type == 'contour':\n",
    "        plt.close('all')\n",
    "        fig = plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        ax1 = plt.subplot(121)\n",
    "        cont1 = ax1.contourf(time, freqs, np.abs(eeg_coeffs), \n",
    "                            levels=20, cmap='RdYlBu_r')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.set_title('EEG Wavelet - Contour')\n",
    "        plt.colorbar(cont1, ax=ax1)\n",
    "        \n",
    "        ax2 = plt.subplot(122)\n",
    "        cont2 = ax2.contourf(time, freqs, np.abs(mag_coeffs), \n",
    "                            levels=20, cmap='RdYlBu_r')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_title('MEG Wavelet - Contour')\n",
    "        plt.colorbar(cont2, ax=ax2)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    elif visualization_type == 'all':\n",
    "        fig = plot_wavelet_visualizations(eeg_data, mag_data, window_idx=window_index, cmap='RdYlBu_r')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Takes ~4min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelet-based EEG shape (alpha, beta, gamma): torch.Size([3, 275, 25706])\n",
      "Wavelet-based MAG shape (alpha, beta, gamma): torch.Size([3, 275, 25706])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e1981afb494783ac8ad5ae6d1853f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Window', max=25705), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_wavelet_transform(data_1d, sampling_rate=250, frequencies=None, wavelet='cmor1.5-1.0'):\n",
    "    \"\"\"\n",
    "    Compute the continuous wavelet transform for a 1D signal.\n",
    "    \n",
    "    Args:\n",
    "        data_1d (1D array): The signal values (e.g., one channel over time).\n",
    "        sampling_rate (float): Sampling rate of the signal (Hz).\n",
    "        frequencies (array): Array of frequencies to analyze. If None, creates a default set.\n",
    "        wavelet (str): Name of the wavelet to use (default: 'cmor1.5-1.0').\n",
    "        \n",
    "    Returns:\n",
    "        (coeffs, freqs): \n",
    "            coeffs is a 2D numpy array of shape (num_freqs, num_time_points)\n",
    "            freqs is a 1D numpy array of frequencies corresponding to each row of coeffs\n",
    "    \"\"\"\n",
    "    if frequencies is None:\n",
    "        # Example frequency range 1-100 Hz\n",
    "        frequencies = np.logspace(np.log10(1), np.log10(100), num=60)\n",
    "    \n",
    "    # Convert frequencies to scales\n",
    "    scales = pywt.frequency2scale(wavelet, frequencies / sampling_rate)\n",
    "    \n",
    "    # Perform continuous wavelet transform\n",
    "    coeffs, _ = pywt.cwt(data_1d, scales, wavelet)\n",
    "    return coeffs, frequencies\n",
    "\n",
    "def extract_wavelet_bands_for_channel(eeg_data, mag_data, eeg_channel=13, mag_channel=21):\n",
    "    \"\"\"\n",
    "    For the given EEG and MAG data, compute wavelet transforms on channels 13 and 21, \n",
    "    keeping only alpha, beta, and gamma frequency bands. \n",
    "    \n",
    "    Returns two tensors:\n",
    "      - wavelet_bands_eeg: (3, time_points, total_windows) for alpha, beta, gamma\n",
    "      - wavelet_bands_mag: (3, time_points, total_windows)\n",
    "    \n",
    "    Where each index on the 0th dimension corresponds to:\n",
    "      0 => alpha band average (8-13 Hz)\n",
    "      1 => beta band average (13-30 Hz)\n",
    "      2 => gamma band average (30-100 Hz)\n",
    "    \"\"\"\n",
    "    # Define frequency bands\n",
    "    band_dict = {\n",
    "        'alpha': (8, 13),\n",
    "        'beta':  (13, 30),\n",
    "        'gamma': (30, 100),\n",
    "    }\n",
    "    \n",
    "    # Grab shapes\n",
    "    # EEG shape => (num_eeg_channels, 275, total_windows)\n",
    "    # We'll focus on just \"eeg_channel\" across all windows\n",
    "    num_windows = eeg_data.shape[2]\n",
    "    time_points = eeg_data.shape[1]\n",
    "    \n",
    "    # Create empty arrays to store the results for alpha, beta, gamma\n",
    "    # shape => (3, time_points, num_windows)\n",
    "    wavelet_bands_eeg = np.zeros((3, time_points, num_windows), dtype=np.float32)\n",
    "    wavelet_bands_mag = np.zeros((3, time_points, num_windows), dtype=np.float32)\n",
    "    \n",
    "    # Iterate over each window, compute wavelet, average power in each band\n",
    "    for w in range(num_windows):\n",
    "        # Extract signals for this window\n",
    "        eeg_signal = eeg_data[eeg_channel, :, w].cpu().numpy()\n",
    "        mag_signal = mag_data[mag_channel, :, w].cpu().numpy()\n",
    "        \n",
    "        # Compute wavelet\n",
    "        eeg_coeffs, freqs = compute_wavelet_transform(eeg_signal)\n",
    "        mag_coeffs, _     = compute_wavelet_transform(mag_signal)\n",
    "        \n",
    "        # For each band (alpha, beta, gamma), compute the average magnitude across freq range\n",
    "        for i, (band_name, (fmin, fmax)) in enumerate(band_dict.items()):\n",
    "            # Identify which rows in the wavelet transform correspond to the band\n",
    "            band_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "            \n",
    "            # EEG band average across freq dimension => shape (time_points,)\n",
    "            band_eeg_vals = np.mean(np.abs(eeg_coeffs[band_mask, :]), axis=0)\n",
    "            wavelet_bands_eeg[i, :, w] = band_eeg_vals\n",
    "            \n",
    "            # MAG band average\n",
    "            band_mag_vals = np.mean(np.abs(mag_coeffs[band_mask, :]), axis=0)\n",
    "            wavelet_bands_mag[i, :, w] = band_mag_vals\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    wavelet_bands_eeg = torch.from_numpy(wavelet_bands_eeg)\n",
    "    wavelet_bands_mag = torch.from_numpy(wavelet_bands_mag)\n",
    "    \n",
    "    return wavelet_bands_eeg, wavelet_bands_mag\n",
    "\n",
    "\n",
    "if eeg_data is not None and mag_data is not None:\n",
    "    wavelet_bands_eeg, wavelet_bands_mag = extract_wavelet_bands_for_channel(eeg_data, mag_data)\n",
    "    \n",
    "    print(\"Wavelet-based EEG shape (alpha, beta, gamma):\", wavelet_bands_eeg.shape)\n",
    "    print(\"Wavelet-based MAG shape (alpha, beta, gamma):\", wavelet_bands_mag.shape)\n",
    "else:\n",
    "    print(\"EEG or MAG data is None, cannot perform wavelet band extraction.\")\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Plotting\n",
    "#########################################\n",
    "def plot_wavelet_bands(wavelet_bands_eeg, wavelet_bands_mag, window_idx):\n",
    "    \"\"\"\n",
    "    Plot the alpha, beta, and gamma bands for both EEG and MEG data for a given window\n",
    "    \"\"\"\n",
    "    bands = ['Alpha (8-13 Hz)', 'Beta (13-30 Hz)', 'Gamma (30-100 Hz)']\n",
    "    time = np.arange(275) / 250  # 275 timepoints at 250Hz = 1.1 seconds\n",
    "    \n",
    "    plt.close('all')\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'Wavelet Bands - Window {window_idx}', fontsize=16)\n",
    "    \n",
    "    # Plot EEG bands (left column)\n",
    "    for i, band_name in enumerate(bands):\n",
    "        axes[i, 0].plot(time, wavelet_bands_eeg[i, :, window_idx], 'r-', label=band_name)\n",
    "        axes[i, 0].set_title(f'EEG {band_name}')\n",
    "        axes[i, 0].set_xlabel('Time (s)')\n",
    "        axes[i, 0].set_ylabel('Magnitude')\n",
    "        axes[i, 0].grid(True)\n",
    "        axes[i, 0].legend()\n",
    "    \n",
    "    # Plot MAG bands (right column)\n",
    "    for i, band_name in enumerate(bands):\n",
    "        axes[i, 1].plot(time, wavelet_bands_mag[i, :, window_idx], 'b-', label=band_name)\n",
    "        axes[i, 1].set_title(f'MEG {band_name}')\n",
    "        axes[i, 1].set_xlabel('Time (s)')\n",
    "        axes[i, 1].set_ylabel('Magnitude')\n",
    "        axes[i, 1].grid(True)\n",
    "        axes[i, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Interactive widget to explore different windows\n",
    "@interact(\n",
    "    window_index=widgets.IntSlider(\n",
    "        min=0, \n",
    "        max=wavelet_bands_eeg.shape[2]-1, \n",
    "        step=1, \n",
    "        value=0, \n",
    "        description='Window'\n",
    "    )\n",
    ")\n",
    "def plot_interactive_bands(window_index):\n",
    "    clear_output(wait=True)\n",
    "    fig = plot_wavelet_bands(wavelet_bands_eeg, wavelet_bands_mag, window_index)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics for this window\n",
    "    print(\"\\nWindow Statistics:\")\n",
    "    for i, band in enumerate(['Alpha', 'Beta', 'Gamma']):\n",
    "        print(f\"\\n{band} Band:\")\n",
    "        print(f\"EEG - Mean: {wavelet_bands_eeg[i, :, window_index].mean():.4f}, \"\n",
    "              f\"Max: {wavelet_bands_eeg[i, :, window_index].max():.4f}\")\n",
    "        print(f\"MEG - Mean: {wavelet_bands_mag[i, :, window_index].mean():.4f}, \"\n",
    "              f\"Max: {wavelet_bands_mag[i, :, window_index].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Mutual Information\n",
    "- Measures shared information between two signals (in the information theory sense)\n",
    "- Lets us know if the signal between eeg & meg shares resemblance.\n",
    "- Formula: MI(X,Y) = Σ Σ P(x,y) * log₂(P(x,y)/(P(x)P(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha band Mutual Information (EEG->MAG), channel 13->21:  0.022188878871665096\n"
     ]
    }
   ],
   "source": [
    "# MI between the EEG (channel 13) and MAG (channel 21) signals across ALL windows.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def bandpass_filter(signal, sf, low_freq, high_freq):\n",
    "    \"\"\"\n",
    "    Perform a simple bandpass filter in the frequency domain by FFT and \n",
    "    removing all frequency components outside [low_freq, high_freq].\n",
    "    \"\"\"\n",
    "    n = len(signal)\n",
    "    # Frequency array (for real FFT up to Nyquist)\n",
    "    freqs = np.fft.rfftfreq(n, 1.0 / sf)\n",
    "    # FFT of the signal\n",
    "    fft_signal = np.fft.rfft(signal)\n",
    "    # Zero out frequencies that are not in the desired band\n",
    "    mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "    fft_signal[~mask] = 0\n",
    "    # Reconstruct filtered signal via IFFT\n",
    "    filtered = np.fft.irfft(fft_signal, n=n)\n",
    "    return filtered\n",
    "\n",
    "def compute_alpha_mutual_information(eeg_data, mag_data, eeg_channel=13, mag_channel=21, alpha_range=(8, 12), sf=250):\n",
    "    \"\"\"\n",
    "    Computes the mutual information for alpha-band EEG and MAG signals across ALL windows.\n",
    "    \n",
    "    eeg_data shape: (num_eeg_channels, num_time_frames, num_windows)\n",
    "    mag_data shape: (num_mag_channels, num_time_frames, num_windows)\n",
    "    \n",
    "    1) Apply bandpass filter in [alpha_range[0], alpha_range[1]] for each window.\n",
    "    2) Concatenate all window data into a single array for EEG alpha, and one for MAG alpha.\n",
    "    3) Compute mutual information using sklearn's mutual_info_regression.\n",
    "    4) Return the MI value.\n",
    "    \"\"\"\n",
    "    low_freq, high_freq = alpha_range\n",
    "\n",
    "    # Prepare lists to accumulate alpha data across all windows\n",
    "    alpha_eeg_all = []\n",
    "    alpha_mag_all = []\n",
    "\n",
    "    # Number of windows\n",
    "    num_windows = eeg_data.shape[2]\n",
    "    \n",
    "    for w in range(num_windows):\n",
    "        # Extract the full EEG and MAG signals for this window\n",
    "        eeg_slice = eeg_data[eeg_channel, :, w]\n",
    "        mag_slice = mag_data[mag_channel, :, w]\n",
    "\n",
    "        # Convert to numpy if on GPU\n",
    "        if hasattr(eeg_slice, 'cpu'):\n",
    "            eeg_slice = eeg_slice.cpu().numpy()\n",
    "        else:\n",
    "            eeg_slice = eeg_slice.numpy()\n",
    "\n",
    "        if hasattr(mag_slice, 'cpu'):\n",
    "            mag_slice = mag_slice.cpu().numpy()\n",
    "        else:\n",
    "            mag_slice = mag_slice.numpy()\n",
    "\n",
    "        # Filter for alpha band\n",
    "        alpha_eeg = bandpass_filter(eeg_slice, sf, low_freq, high_freq)\n",
    "        alpha_mag = bandpass_filter(mag_slice, sf, low_freq, high_freq)\n",
    "\n",
    "        # Accumulate\n",
    "        alpha_eeg_all.append(alpha_eeg)\n",
    "        alpha_mag_all.append(alpha_mag)\n",
    "\n",
    "    # Concatenate all windows into single 1D arrays\n",
    "    alpha_eeg_all = np.concatenate(alpha_eeg_all, axis=0)\n",
    "    alpha_mag_all = np.concatenate(alpha_mag_all, axis=0)\n",
    "\n",
    "    # sklearn mutual_info_regression requires shapes:\n",
    "    # X: (n_samples, n_features), y: (n_samples,)\n",
    "    alpha_eeg_all = alpha_eeg_all.reshape(-1, 1)\n",
    "\n",
    "    # Compute Mutual Information (for continuous data)\n",
    "    mi_value = mutual_info_regression(alpha_eeg_all, alpha_mag_all, random_state=42)\n",
    "    # mutual_info_regression returns an array of MI values for each feature column;\n",
    "    # we only have one feature column, so take mi_value[0].\n",
    "    return mi_value[0]\n",
    "\n",
    "alpha_mi = compute_alpha_mutual_information(eeg_data, mag_data, eeg_channel=13, mag_channel=21)\n",
    "print(\"Alpha band Mutual Information (EEG->MAG), channel 13->21: \", alpha_mi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synaptech_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
